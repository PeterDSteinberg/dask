{
 "metadata": {
  "name": "",
  "signature": "sha256:9843d081a9d563da02851a3aaf58a892bb10201cd63456cde4fa7ec32a2ae0a5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Scikit-Learn Classification and Regression for Dask Arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Import the classes and later abstract their <code>partial_fit</code> methods"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function, division\n",
      "import inspect\n",
      "import itertools\n",
      "import dask.array as da\n",
      "import numpy as np\n",
      "import random\n",
      "import re\n",
      "from pprint import pprint\n",
      "import sys\n",
      "import tarfile\n",
      "import time\n",
      "from dask.array.core import rec_concatenate, Array\n",
      "from functools import partial\n",
      "from itertools import count\n",
      "from operator import getitem\n",
      "from pprint import pformat\n",
      "from sklearn.cluster import MiniBatchKMeans\n",
      "from sklearn.datasets import get_data_home\n",
      "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
      "from sklearn.externals.six.moves import html_parser\n",
      "from sklearn.externals.six.moves import urllib\n",
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "from sklearn.linear_model import PassiveAggressiveClassifier\n",
      "from sklearn.linear_model import PassiveAggressiveRegressor\n",
      "from sklearn.linear_model import Perceptron\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.linear_model import SGDRegressor\n",
      "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
      "from toolz import merge\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### A dictionary of the sci-kit learn classes that could be supported.  Each of these has a <code>partial_fit</code> method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_names  = ('sample-%d' % i for i in count(1))\n",
      "partial_fit_algos = {\n",
      "    'SGDClassifier': SGDClassifier,\n",
      "    'SGDRegressor':SGDRegressor,\n",
      "    'Perceptron': Perceptron,\n",
      "    'PassiveAggressiveClassifier': PassiveAggressiveClassifier,\n",
      "    'PassiveAggressiveRegressor':PassiveAggressiveRegressor,\n",
      "    'MultinomialNB': MultinomialNB,\n",
      "    'BernoulliNB': BernoulliNB,\n",
      "    'MiniBatchDictionaryLearning': MiniBatchDictionaryLearning,\n",
      "    'MiniBatchKMeans': MiniBatchKMeans,\n",
      "}\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### A common base class to abstract <code>partial_fit</code> methods."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class DaskMLBase(object): \n",
      "    \"\"\"Classes by the same name as sklearn classes\n",
      "    inherit from DaskMLBase.\n",
      "\n",
      "    It standardizes the use of partial_fit methods \n",
      "    of sklearn classes for use with dask arrays. \n",
      "\n",
      "    Parameters:\n",
      "\n",
      "        Positional args:\n",
      "            args_to_cls: list/tuple\n",
      "                args that go to the original sklearn class\n",
      "                initialization, typically []\n",
      "            kwargs_to_cls: dict \n",
      "                kwargs that go to the original sklearn class\n",
      "                initialization. see sklearn docs\n",
      "            X: 2-d dask array\n",
      "                Training data X \n",
      "        Keywork args:\n",
      "            Y: 1-d or 2-d dask array:\n",
      "                True Y samples, 1- or 2-d,\n",
      "                depending on sklearn class.\n",
      "                Y.shape[0] === X.shape[0] \n",
      "            sample_weight: None/1-d dask array \n",
      "                sample weights to be applied in \n",
      "                training, if any.\n",
      "                sample_weight.shape[0] == X.shape[0]\n",
      "            sample_gridx: int \n",
      "                the regular blockshape (row count) \n",
      "                to which the X,Y, sample_weight\n",
      "                should be reblocked.  Column blocking \n",
      "                is unaffected.\n",
      "            batch_size: int\n",
      "                How many rows to use for each sample \n",
      "                (This is automatically inserted in \n",
      "                    kwargs_to_cls when needed.)\n",
      "            n_batches: int \n",
      "                How many batches of samples.\n",
      "            callback: None/callable\n",
      "                Run this on each batch\n",
      "            shuffle: bool\n",
      "                If True, shuffle among blocks using Poisson\n",
      "                distribution (slow), else select blocks randomly\n",
      "                using full slices of each block until sample\n",
      "                size is met.\n",
      "    \"\"\"\n",
      "    # These are the methods that require\n",
      "    # all possible classes to be known in advance.\n",
      "    requires_all_classes = ('MultinomialNB','BernoulliNB',\n",
      "                            'Perceptron','SGDClassifier',\n",
      "                            'PassiveAggressiveClassifier')\n",
      "    cls_str = None # to over-ride this in each class\n",
      "    def __init__(self, \n",
      "                args_to_cls, \n",
      "                kwargs_to_cls, \n",
      "                X, \n",
      "                Y=None,\n",
      "                sample_weight=None,\n",
      "                sample_gridx=500,\n",
      "                batch_size=10000,\n",
      "                n_batches=10,\n",
      "                callback=None,\n",
      "                shuffle=False):\n",
      "        # get the class object\n",
      "        self.cls = partial_fit_algos[self.cls_str]\n",
      "        # reblock the row dimension uniformly of X\n",
      "        self.X = X.reblock(blockshape=(sample_gridx, X.shape[1])) \n",
      "        # reblock sample_weight if given\n",
      "        if sample_weight is not None:\n",
      "            self.sample_weight = sample_weight.reblock(blockshape=(sample_gridx,))\n",
      "        else:\n",
      "            self.sample_weight = None\n",
      "        # determine whether Y (true samples)\n",
      "        # is given and its dimension if so.\n",
      "        if (Y is not None) and len(Y.shape) == 2:\n",
      "            yb = (sample_gridx, Y.shape[1])\n",
      "        else:\n",
      "            yb = (sample_gridx,)\n",
      "        # make sure X, Y, sample_weights\n",
      "        # are all on same row blocks.\n",
      "        if Y is not None:\n",
      "            self.Y = Y.reblock(blockshape=yb)\n",
      "        else:\n",
      "            self.Y = None\n",
      "        # save params\n",
      "        self.sample_gridx = sample_gridx\n",
      "        self.shuffle = shuffle\n",
      "        self.batch_size = batch_size\n",
      "        self.n_batches = n_batches\n",
      "        self.callback = callback\n",
      "        # automate some initialization\n",
      "        # of classes for ml\n",
      "        try:\n",
      "            self.spec = inspect.getargspec(\n",
      "                            self.cls.__init__\n",
      "                        ).args\n",
      "        except:\n",
      "            self.spec = {}\n",
      "        if 'batch_size' in self.spec:\n",
      "            kwargs_to_cls['batch_size'] = batch_size\n",
      "        if 'shuffle' in self.spec:\n",
      "            kwargs_to_cls['shuffle'] = False\n",
      "        # initialize model\n",
      "        self.model = self.cls(*args_to_cls, \n",
      "                                **kwargs_to_cls)\n",
      "        # initialize scores and history\n",
      "        try:\n",
      "            self.score_spec = inspect.getargspec(\n",
      "                                    self.model.score\n",
      "                                ).args\n",
      "        except:\n",
      "            self.score_spec = {}\n",
      "        self.stats = {\n",
      "                     'iter_offset': 0, \n",
      "                     'score': 0.0,\n",
      "                     'history': [], \n",
      "                     't0': time.time(),\n",
      "                     'total_fit_time': 0.0,\n",
      "            }\n",
      "        \n",
      "\n",
      "    def __repr__(self):\n",
      "        s = pformat(self.stats)\n",
      "        return \"Model:\\n%r\\nStats:\\n%s\\n\"%(self.model, s)\n",
      "    def _row_getter(self, name, getarg, grab, twod=True):\n",
      "        \"\"\"Internal utility for forming slices \n",
      "        needed in dask array DAG's\"\"\"\n",
      "        key = (name,0)\n",
      "        if twod:\n",
      "            key += (0,)\n",
      "            slic_arg = lambda g: (slice(g,None,None),slice(None,None,None))\n",
      "        else:\n",
      "            slic_arg = lambda g: slice(g,None,None)\n",
      "        if grab is None:\n",
      "            slic = (slice(None, None, None),)*2\n",
      "            return (key, (getitem, getarg, slic))\n",
      "        kv = ( key, \n",
      "            (rec_concatenate,\n",
      "                [(getitem, getarg, slic_arg(g)) for g in grab],\n",
      "            )\n",
      "        )\n",
      "        return kv\n",
      "    def get_sample(self, shuffle=False):\n",
      "        \"\"\"get_sample(shuffle=False)\n",
      "        If shuffle is True,then the \n",
      "        Poisson distribution is used \n",
      "        to sample randomly within all blocks on \n",
      "        each sample (slow).  If shuffle is False, then\n",
      "         blocks are selected at random using full \n",
      "         slices of each block until the sample \n",
      "         size is met.\n",
      "\n",
      "         \"\"\"\n",
      "        cat_argx = []\n",
      "        cat_argy = []\n",
      "        cat_argsw = []\n",
      "        # Poisson number\n",
      "        M = self.batch_size * self.sample_gridx / self.X.shape[0]\n",
      "        M = int(np.ceil(M))\n",
      "        xname = next(sample_names)\n",
      "        yname = next(sample_names)\n",
      "        if self.sample_weight:\n",
      "            swname = next(sample_names)\n",
      "        row_count = 0\n",
      "        choices = tuple(range(self.sample_gridx))\n",
      "        # all possible row blocks\n",
      "        blks = list(range(len(self.X.blockdims[0])))\n",
      "        np.random.shuffle(blks)\n",
      "        if shuffle:\n",
      "            # choose small number from each block\n",
      "            limit = len(blks)\n",
      "        else:\n",
      "            # choose all from small number of blocks\n",
      "            limit = self.batch_size / self.sample_gridx\n",
      "            limit = int(np.ceil(limit))\n",
      "        for blk_row_idx in blks[:limit]:\n",
      "            dskx, dsky, dsksw = {},{},{}\n",
      "            indx =  (self.X.name, blk_row_idx, 0)\n",
      "            if shuffle:\n",
      "                # how many from this block\n",
      "                grab_count = np.random.poisson(M)\n",
      "                if not grab_count:\n",
      "                    # chose 0 skip\n",
      "                    continue\n",
      "                row_count += grab_count\n",
      "                # random list of row inds\n",
      "                grab = [np.random.choice(choices) for _ in range(grab_count)]\n",
      "            else:\n",
      "                # do full slice of this block\n",
      "                grab = None \n",
      "                grab_count = self.sample_gridx\n",
      "            k,v = self._row_getter(xname, \n",
      "                                   indx,\n",
      "                                   grab,\n",
      "                                   twod=True)\n",
      "            dskx[k] = v \n",
      "            if self.Y is not None:\n",
      "                indy = (self.Y.name, ) + indx[1:len(self.Y.shape) + 1]\n",
      "                k,v = self._row_getter(yname, \n",
      "                                      indy,\n",
      "                                      grab,\n",
      "                                      twod=len(self.Y.shape)==2)\n",
      "                dsky[k] = v \n",
      "            if self.sample_weight:\n",
      "                indsw = (self.sample_weight.name,) + (indx[1],)\n",
      "                k,v = self._row_getter(swname, \n",
      "                                        indsw,\n",
      "                                        grab,\n",
      "                                        twod=False)\n",
      "                dsksw[k] = v\n",
      "                cat_argsw.append(Array(merge(dsksw, self.sample_weight.dask),\n",
      "                    swname,\n",
      "                    shape=(grab_count,1),\n",
      "                    blockshape=(grab_count,1)\n",
      "                    ).compute())\n",
      "            cat_argx.append(Array(merge(dskx, self.X.dask),\n",
      "                    xname,\n",
      "                    shape=(grab_count, self.X.shape[1]),\n",
      "                    blockshape=(grab_count, self.X.shape[1])).compute())\n",
      "            if self.Y is not None:\n",
      "                if len(self.Y.shape) == 2:\n",
      "                    y_blockshape = (grab_count, self.Y.shape[1])\n",
      "                else:\n",
      "                    y_blockshape = (grab_count,)\n",
      "                cat_argy.append(Array(merge(dsky, self.Y.dask),\n",
      "                    yname,\n",
      "                    shape=y_blockshape,\n",
      "                    blockshape=y_blockshape).compute())\n",
      "\n",
      "        sample_x = np.concatenate(cat_argx)\n",
      "        if self.Y is not None:\n",
      "            sample_y = np.concatenate(cat_argy)\n",
      "        else:\n",
      "            sample_y = None\n",
      "        if self.sample_weight:\n",
      "            sample_weight = np.concatenate(cat_argsw)\n",
      "        else:\n",
      "            sample_weight = None\n",
      "        return (self.transform_x(sample_x), \n",
      "                    self.transform_y(sample_y), \n",
      "                    sample_weight)\n",
      "    def transform_x(self, x):\n",
      "        \"\"\"Override if needed to transform \n",
      "        a 2-d numpy array X that is a sample\n",
      "        from dask X.\"\"\"\n",
      "        return x \n",
      "    def transform_y(self, y):\n",
      "        \"\"\"Override if needed to transform\n",
      "        a 1-d numpy array Y that is a sample from \n",
      "        dask Y.\"\"\"\n",
      "        return y\n",
      "    def get_all_classes(self):\n",
      "        \"\"\" Overriding this method is required \n",
      "        if using an sklearn method that requires \n",
      "        all possible classes to be known in advance.\"\"\"\n",
      "        raise ValueError(\n",
      "                \"\"\"Override get_all_classes to return \n",
      "all possible classes as list.  Required for %r\n",
      "See sklearn docs. \"\"\" % self.cls)\n",
      "\n",
      "    def partial_fit(self):\n",
      "        \"\"\" \n",
      "        partial_fit(self)\n",
      "\n",
      "        Standardizes arguments to partial_fit methods of \n",
      "        sklearn classes to allow X, Y, and sample_weight \n",
      "        to be dask arrays.\n",
      "\n",
      "        \"\"\"\n",
      "        samp = self.get_sample(shuffle=self.shuffle)\n",
      "        sample_x, sample_y, sample_weight = samp\n",
      "        if self.cls_str in self.requires_all_classes:\n",
      "            kwargs = {'classes': self.get_all_classes()}\n",
      "        else:\n",
      "            kwargs = {}\n",
      "        if 'sample_weight' in self.spec and self.sample_weight is not None:\n",
      "            kwargs['sample_weight'] = sample_weight\n",
      "        if 'iter_offset' in self.spec:\n",
      "            kwargs['iter_offset'] = self.stats['iter_offset']\n",
      "        if not kwargs:\n",
      "            self.model.partial_fit(sample_x, sample_y)\n",
      "        else:\n",
      "            self.model.partial_fit(sample_x, sample_y, **kwargs)\n",
      "        self.stats['iter_offset'] += sample_x.shape[0]\n",
      "        if hasattr(self.model, 'score'):\n",
      "            score_args = [sample_x]\n",
      "            if 'y' in self.score_spec or 'Y' in self.score_spec:\n",
      "                score_args.append(sample_y)\n",
      "            if 'sample_weight' in self.score_spec:\n",
      "                self.stats['score'] = self.model.score(*score_args, \n",
      "                                        sample_weight=sample_weight)\n",
      "            else:\n",
      "                self.stats['score'] = self.model.score(*score_args)\n",
      "            self.stats['history'].append((self.stats['iter_offset'], self.stats['score']))\n",
      "        self.stats['total_fit_time'] = time.time() - self.stats['t0']\n",
      "        if callable(self.callback): \n",
      "            self.callback()\n",
      "    \n",
      "    def fit(self):\n",
      "        for step in range(self.n_batches):\n",
      "            self.partial_fit()\n",
      "            self.step = step\n",
      "            if self.stop():\n",
      "                break\n",
      "        scores = ([h[1] for h in self.stats['history']])\n",
      "        self.stats['score_summary'] = {\n",
      "            'mean': np.mean(scores),\n",
      "            'median': np.median(scores),\n",
      "            'min': np.min(scores),\n",
      "            'max': np.max(scores),\n",
      "        }\n",
      "    def stop(self):\n",
      "        \"\"\" Override this if needed.\n",
      "        Return True to stop after a partial_fit\n",
      "        step.\n",
      "        \"\"\"\n",
      "        return False\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define machine learning classes that inherit from the base class above"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "class SGDClassifier(DaskMLBase):\n",
      "    cls_str = 'SGDClassifier'\n",
      "\n",
      "\n",
      "class SGDRegressor(DaskMLBase):\n",
      "    cls_str = 'SGDRegressor'\n",
      "\n",
      "\n",
      "class Perceptron(DaskMLBase):\n",
      "    cls_str = 'Perceptron'\n",
      "\n",
      "\n",
      "class PassiveAggressiveClassifier(DaskMLBase):\n",
      "    cls_str = 'PassiveAggressiveClassifier'\n",
      "\n",
      "\n",
      "class PassiveAggressiveRegressor(DaskMLBase):\n",
      "    cls_str = 'PassiveAggressiveRegressor'\n",
      "\n",
      "\n",
      "class MultinomialNB(DaskMLBase):\n",
      "    cls_str = 'MultinomialNB'\n",
      "\n",
      "\n",
      "class BernoulliNB(DaskMLBase):\n",
      "    cls_str = 'BernoulliNB'\n",
      "\n",
      "\n",
      "class MiniBatchDictionaryLearning(DaskMLBase):\n",
      "    cls_str = 'MiniBatchDictionaryLearning'\n",
      "\n",
      "\n",
      "class MiniBatchKMeans(DaskMLBase):\n",
      "    cls_str = \"MiniBatchKMeans\"\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using the learning classes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Here are some of the kwargs for the modified machine learning algorithms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "default_kwargs = {\n",
      "            \n",
      "            'batch_size': 1000,       # sample size - each batch\n",
      "            'n_batches': 4,           # how many batches\n",
      "            'sample_gridx': 500,      # to what row count should the row dimension be reblocked\n",
      "            'shuffle': False,         # True will do Poisson sampling, see def get_sample_above\n",
      "        }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Doing a simple Bernoulli Naive Bayes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def test_bernoullinb():\n",
      "    global runner\n",
      "    rows = 10000\n",
      "    cols = 2\n",
      "    X = np.zeros((rows, cols))\n",
      "    X[1::2, 0] = 1\n",
      "    X[0::2, 1] = 1\n",
      "    X[1::2, 1] = 0\n",
      "    X[0::2, 0] = 0\n",
      "    Y = np.zeros((rows, 1))\n",
      "    Y[::2] = 1\n",
      "    X = da.from_array(X, \n",
      "                    shape=X.shape, \n",
      "                    blockshape=(100, 2))\n",
      "    Y = da.from_array(Y, \n",
      "                    shape=Y.shape, \n",
      "                    blockshape=(100, 1))\n",
      "    args_to_cls = []\n",
      "    kwargs_to_cls = {}\n",
      "    kwargs = default_kwargs.copy()\n",
      "    kwargs['Y'] = Y\n",
      "    runner = BernoulliNB(args_to_cls, \n",
      "                kwargs_to_cls, \n",
      "                X,\n",
      "                **kwargs)\n",
      "    runner.get_all_classes= lambda: [0, 1]\n",
      "    runner.fit()\n",
      "    print(\"BernoulliNB\\n\",runner)\n",
      "    assert runner.stats['score_summary']['mean'] > .92\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_bernoullinb()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB\n",
        " Model:\n",
        "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Stats:\n",
        "{'history': [(1000, 1.0), (2000, 1.0), (3000, 1.0), (4000, 1.0)],\n",
        " 'iter_offset': 4000,\n",
        " 'score': 1.0,\n",
        " 'score_summary': {'max': 1.0, 'mean': 1.0, 'median': 1.0, 'min': 1.0},\n",
        " 't0': 1427899792.029886,\n",
        " 'total_fit_time': 1.7255070209503174}\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Doing several classifiers on the same problem"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ml_group1 = ('PassiveAggressiveClassifier',\n",
      "            'SGDRegressor',\n",
      "            'SGDClassifier',\n",
      "            'Perceptron',\n",
      "            )\n",
      "def test_several_ml():\n",
      "    global runner   \n",
      "    rows = 10000\n",
      "    cols = 5\n",
      "    X = np.ones((rows, cols)) * 2\n",
      "    X[::2,:] = 0\n",
      "    X += np.random.uniform(0,.05, rows * cols).reshape((rows, cols))\n",
      "    Y = np.ones((rows,))\n",
      "    Y[::2] = 0\n",
      "    batch_size = rows // 2\n",
      "    x_block = batch_size // 10\n",
      "    Y = da.from_array(Y,\n",
      "                      shape=Y.shape, \n",
      "                      blockshape=(x_block,))\n",
      "    X = da.from_array(X,\n",
      "                     shape=X.shape, \n",
      "                     blockshape=(x_block, 1))\n",
      "    for k in ml_group1:  # for each algorithm....\n",
      "        cls =  globals()[k]\n",
      "        kwargs =    {\n",
      "                    'sample_gridx': 200,\n",
      "                    'batch_size': 4000,\n",
      "                    'n_batches': 2,\n",
      "                    'Y': Y,\n",
      "                    'shuffle': False,\n",
      "                    }\n",
      "        args_to_cls = []\n",
      "        kwargs_to_cls = {}\n",
      "        runner = cls(args_to_cls,\n",
      "                    kwargs_to_cls,\n",
      "                    X,\n",
      "                    **kwargs)\n",
      "        runner.get_all_classes = lambda: [0, 1]\n",
      "        runner.fit()\n",
      "        print('Model',k,'Score Summary:')\n",
      "        pprint(runner.stats['score_summary'])\n",
      "        assert runner.stats['score_summary']['mean'] > .92\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_several_ml()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Model PassiveAggressiveClassifier Score Summary:\n",
        "{'max': 1.0, 'mean': 1.0, 'median': 1.0, 'min': 1.0}\n",
        "Model"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " SGDRegressor Score Summary:\n",
        "{'max': 0.99995588086472798,\n",
        " 'mean': 0.99994914387862743,\n",
        " 'median': 0.99994914387862743,\n",
        " 'min': 0.99994240689252678}\n",
        "Model"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " SGDClassifier Score Summary:\n",
        "{'max': 1.0, 'mean': 1.0, 'median': 1.0, 'min': 1.0}\n",
        "Model"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Perceptron Score Summary:\n",
        "{'max': 1.0, 'mean': 1.0, 'median': 1.0, 'min': 1.0}\n"
       ]
      }
     ],
     "prompt_number": 56
    }
   ],
   "metadata": {}
  }
 ]
}